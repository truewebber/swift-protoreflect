/**
 * üì¶ SwiftProtoReflect Example: Batch Operations
 *
 * –û–ø–∏—Å–∞–Ω–∏–µ: –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–∞—Å—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
 * –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏: Batch processing, Mass operations, Performance optimization
 * –°–ª–æ–∂–Ω–æ—Å—Ç—å: üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π
 * –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: < 25 —Å–µ–∫—É–Ω–¥
 */

import ExampleUtils
import Foundation
import SwiftProtoReflect

@main
struct BatchOperationsExample {
  static func main() throws {
    ExampleUtils.printHeader("üì¶ Batch Operations - Mass Message Processing")

    try demonstrateBatchCreation()
    try demonstrateBatchSerialization()
    try demonstrateBatchValidation()
    try demonstrateBatchTransformation()
    try demonstrateParallelProcessing()
    try demonstrateMemoryOptimization()

    ExampleUtils.printSuccess("Batch operations demonstration completed!")
    ExampleUtils.printNext([
      "–°–ª–µ–¥—É—é—â–∏–π –ø—Ä–∏–º–µ—Ä: memory-optimization.swift - —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏",
      "–ò–∑—É—á–∏—Ç–µ —Ç–∞–∫–∂–µ: thread-safety.swift - –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
    ])
  }

  // MARK: - Batch Creation

  private static func demonstrateBatchCreation() throws {
    ExampleUtils.printStep(1, "Batch Message Creation")

    print("  üèó  Creating message schema...")
    var userFile = FileDescriptor(name: "user.proto", package: "com.batch")
    var userDescriptor = MessageDescriptor(name: "User", parent: userFile)

    userDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .string))
    userDescriptor.addField(FieldDescriptor(name: "name", number: 2, type: .string))
    userDescriptor.addField(FieldDescriptor(name: "email", number: 3, type: .string))
    userDescriptor.addField(FieldDescriptor(name: "age", number: 4, type: .int32))
    userDescriptor.addField(FieldDescriptor(name: "is_premium", number: 5, type: .bool))

    userFile.addMessage(userDescriptor)

    // Batch —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
    let batchSize = 5000
    print("  üì¶ Creating \(batchSize) messages in batch...")

    let factory = MessageFactory()
    var messages: [DynamicMessage] = []

    let creationTime = try ExampleUtils.measureTime {
      for i in 1...batchSize {
        var user = factory.createMessage(from: userDescriptor)
        try user.set("USER-\(String(format: "%04d", i))", forField: "id")
        try user.set("User \(i)", forField: "name")
        try user.set("user\(i)@company.com", forField: "email")
        try user.set(Int32.random(in: 18...65), forField: "age")
        try user.set(Bool.random(), forField: "is_premium")
        messages.append(user)
      }
    }

    ExampleUtils.printTiming("Batch creation (\(batchSize) messages)", time: creationTime.time)

    let _ = Double(batchSize) / creationTime.time  // throughput

    print("\n  üìä Creation Results:")
    let creationData = [
      ["Metric": "Messages Created", "Value": "\(batchSize)", "Performance": "Success"],
      [
        "Metric": "Creation Time", "Value": "\(String(format: "%.3f", creationTime.time * 1000))ms",
        "Performance": "Excellent",
      ],
      [
        "Metric": "Throughput", "Value": "\(String(format: "%.0f", Double(batchSize)/creationTime.time)) msg/s",
        "Performance": "High",
      ],
      ["Metric": "Memory Usage", "Value": "~\(batchSize * 300) bytes", "Performance": "Efficient"],
    ]
    ExampleUtils.printDataTable(creationData, title: "Batch Creation Metrics")
  }

  // MARK: - Batch Serialization

  private static func demonstrateBatchSerialization() throws {
    ExampleUtils.printStep(2, "Batch Serialization Operations")

    print("  üì¶ Preparing messages for serialization...")

    // –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    var dataFile = FileDescriptor(name: "data.proto", package: "com.data")
    var dataDescriptor = MessageDescriptor(name: "DataRecord", parent: dataFile)

    dataDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .int64))
    dataDescriptor.addField(FieldDescriptor(name: "timestamp", number: 2, type: .int64))
    dataDescriptor.addField(FieldDescriptor(name: "value", number: 3, type: .double))
    dataDescriptor.addField(FieldDescriptor(name: "metadata", number: 4, type: .string))

    dataFile.addMessage(dataDescriptor)

    let recordCount = 2000
    let factory = MessageFactory()
    var records: [DynamicMessage] = []

    // –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    for i in 1...recordCount {
      var record = factory.createMessage(from: dataDescriptor)
      try record.set(Int64(i), forField: "id")
      try record.set(Int64(Date().timeIntervalSince1970 * 1000), forField: "timestamp")
      try record.set(Double.random(in: -100...100), forField: "value")
      try record.set("metadata_\(i)", forField: "metadata")

      records.append(record)
    }

    // Batch binary —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print("\n  üîÑ Batch binary serialization...")

    let binarySerializer = BinarySerializer()
    var binaryData: [Data] = []

    let binaryTime = try ExampleUtils.measureTime {
      binaryData = try records.map { try binarySerializer.serialize($0) }
    }

    ExampleUtils.printTiming("Binary serialization (\(recordCount) records)", time: binaryTime.time)

    // Batch JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print("\n  üîÑ Batch JSON serialization...")

    let jsonSerializer = JSONSerializer()
    var jsonData: [Data] = []

    let jsonTime = try ExampleUtils.measureTime {
      jsonData = try records.map { try jsonSerializer.serialize($0) }
    }

    ExampleUtils.printTiming("JSON serialization (\(recordCount) records)", time: jsonTime.time)

    // –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    let totalBinarySize = binaryData.reduce(0) { $0 + $1.count }
    let totalJsonSize = jsonData.reduce(0) { $0 + $1.count }
    let _ = Double(totalJsonSize) / Double(totalBinarySize)  // compressionRatio

    print("\n  üìä Serialization Comparison:")
    let serializationData = [
      [
        "Format": "Binary", "Total Size": "\(totalBinarySize) bytes",
        "Avg Size/Record": "\(totalBinarySize/recordCount) bytes",
        "Throughput": "\(String(format: "%.0f", Double(recordCount)/binaryTime.time)) rec/s",
      ],
      [
        "Format": "JSON", "Total Size": "\(totalJsonSize) bytes",
        "Avg Size/Record": "\(totalJsonSize/recordCount) bytes",
        "Throughput": "\(String(format: "%.0f", Double(recordCount)/jsonTime.time)) rec/s",
      ],
      [
        "Format": "Efficiency",
        "Total Size": "\(String(format: "%.1f", Double(totalBinarySize)/Double(totalJsonSize)*100))% of JSON",
        "Avg Size/Record": "Binary saves \(totalJsonSize-totalBinarySize) bytes",
        "Throughput": "Binary is \(String(format: "%.1fx", jsonTime.time/binaryTime.time)) faster",
      ],
    ]
    ExampleUtils.printDataTable(serializationData, title: "Serialization Performance")
  }

  // MARK: - Batch Validation

  private static func demonstrateBatchValidation() throws {
    ExampleUtils.printStep(3, "Batch Validation and Quality Control")

    print("  üîç Creating dataset with validation scenarios...")

    var productFile = FileDescriptor(name: "product.proto", package: "com.validation")
    var productDescriptor = MessageDescriptor(name: "Product", parent: productFile)

    productDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .string))
    productDescriptor.addField(FieldDescriptor(name: "name", number: 2, type: .string))
    productDescriptor.addField(FieldDescriptor(name: "price", number: 3, type: .double))
    productDescriptor.addField(FieldDescriptor(name: "category", number: 4, type: .string))
    productDescriptor.addField(FieldDescriptor(name: "in_stock", number: 5, type: .bool))

    productFile.addMessage(productDescriptor)

    let factory = MessageFactory()
    var products: [DynamicMessage] = []
    var validationResults: [String: Int] = [:]

    // –°–æ–∑–¥–∞–Ω–∏–µ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö (–≤–∞–ª–∏–¥–Ω—ã–µ –∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ)
    for i in 1...1000 {
      var product = factory.createMessage(from: productDescriptor)

      // –ù–∞–º–µ—Ä–µ–Ω–Ω–æ —Å–æ–∑–¥–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∑–∞–ø–∏—Å–∏
      let isValid = i % 10 != 0  // 10% –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö

      if isValid {
        try product.set("PROD-\(String(format: "%04d", i))", forField: "id")
        try product.set("Product \(i)", forField: "name")
        try product.set(Double.random(in: 1...1000), forField: "price")
        try product.set(["Electronics", "Clothing", "Books", "Home"].randomElement()!, forField: "category")
        try product.set(Bool.random(), forField: "in_stock")
      }
      else {
        // –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        try product.set("", forField: "id")  // –ü—É—Å—Ç–æ–π ID
        try product.set("Invalid Product", forField: "name")
        try product.set(-1.0, forField: "price")  // –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ü–µ–Ω–∞
        try product.set("", forField: "category")  // –ü—É—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        try product.set(false, forField: "in_stock")
      }

      products.append(product)
    }

    // Batch –≤–∞–ª–∏–¥–∞—Ü–∏—è
    print("\n  üîç Running batch validation...")

    let validationTime = ExampleUtils.measureTime {
      for (_, product) in products.enumerated() {
        var errors: [String] = []

        // –í–∞–ª–∏–¥–∞—Ü–∏—è ID
        if let id = try? product.get(forField: "id") as? String, id.isEmpty {
          errors.append("Empty ID")
        }

        // –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–Ω—ã
        if let price = try? product.get(forField: "price") as? Double, price < 0 {
          errors.append("Negative price")
        }

        // –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if let category = try? product.get(forField: "category") as? String, category.isEmpty {
          errors.append("Empty category")
        }

        // –ü–æ–¥—Å—á–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if errors.isEmpty {
          validationResults["valid", default: 0] += 1
        }
        else {
          validationResults["invalid", default: 0] += 1
          for error in errors {
            validationResults[error, default: 0] += 1
          }
        }
      }
    }

    ExampleUtils.printTiming("Batch validation (\(products.count) products)", time: validationTime.time)

    // –û—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    print("\n  üìä Validation Results:")
    let validCount = validationResults["valid"] ?? 0
    let _ = validationResults["invalid"] ?? 0  // invalidCount
    let validationRate = Double(validCount) / Double(products.count) * 100

    let validationData = [
      [
        "Category": "Valid Products", "Count": "\(validCount)",
        "Percentage": "\(String(format: "%.1f", validationRate))%",
      ],
      [
        "Category": "Invalid Products", "Count": "\(products.count - validCount)",
        "Percentage": "\(String(format: "%.1f", 100.0 - validationRate))%",
      ],
      ["Category": "Total Products", "Count": "\(products.count)", "Percentage": "100.0%"],
    ]

    ExampleUtils.printDataTable(validationData, title: "Batch Validation Results")
  }

  // MARK: - Batch Transformation

  private static func demonstrateBatchTransformation() throws {
    ExampleUtils.printStep(4, "Batch Data Transformation")

    print("  üîÑ Preparing data transformation pipeline...")

    // –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    var sourceFile = FileDescriptor(name: "source.proto", package: "com.transform")
    var sourceDescriptor = MessageDescriptor(name: "SourceRecord", parent: sourceFile)

    sourceDescriptor.addField(FieldDescriptor(name: "raw_id", number: 1, type: .string))
    sourceDescriptor.addField(FieldDescriptor(name: "raw_value", number: 2, type: .string))
    sourceDescriptor.addField(FieldDescriptor(name: "raw_timestamp", number: 3, type: .string))

    // –¶–µ–ª–µ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
    var targetDescriptor = MessageDescriptor(name: "ProcessedRecord", parent: sourceFile)
    targetDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .int64))
    targetDescriptor.addField(FieldDescriptor(name: "value", number: 2, type: .double))
    targetDescriptor.addField(FieldDescriptor(name: "timestamp", number: 3, type: .int64))
    targetDescriptor.addField(FieldDescriptor(name: "processed_at", number: 4, type: .int64))

    sourceFile.addMessage(sourceDescriptor)
    sourceFile.addMessage(targetDescriptor)

    let transformCount = 1500
    let factory = MessageFactory()
    var sourceRecords: [DynamicMessage] = []

    // –°–æ–∑–¥–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    for i in 1...transformCount {
      var source = factory.createMessage(from: sourceDescriptor)
      try source.set("RAW_\(i)", forField: "raw_id")
      try source.set("\(Double.random(in: 0...100))", forField: "raw_value")
      try source.set("\(Date().timeIntervalSince1970)", forField: "raw_timestamp")

      sourceRecords.append(source)
    }

    print("  üìä Created \(transformCount) source records")

    // Batch —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è
    print("\n  üîÑ Applying batch transformation...")

    var processedRecords: [DynamicMessage] = []

    let transformTime = try ExampleUtils.measureTime {
      for source in sourceRecords {
        var processed = factory.createMessage(from: targetDescriptor)
        // –ü–∞—Ä—Å–∏–Ω–≥ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if let rawId = try source.get(forField: "raw_id") as? String,
          let idNum = Int64(rawId.replacingOccurrences(of: "RAW_", with: ""))
        {
          try processed.set(idNum, forField: "id")
        }

        if let rawValue = try source.get(forField: "raw_value") as? String,
          let doubleValue = Double(rawValue)
        {
          try processed.set(doubleValue, forField: "value")
        }

        if let rawTimestamp = try source.get(forField: "raw_timestamp") as? String,
          let timestampValue = Double(rawTimestamp)
        {
          try processed.set(Int64(timestampValue), forField: "timestamp")
        }

        try processed.set(Int64(Date().timeIntervalSince1970), forField: "processed_at")

        processedRecords.append(processed)
      }
    }

    ExampleUtils.printTiming("Batch transformation (\(transformCount) records)", time: transformTime.time)

    // –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    let _ = Double(transformCount) / transformTime.time  // transformThroughput

    print("\n  üìä Transformation Results:")
    let transformationData = [
      ["Metric": "Records Processed", "Value": "\(processedRecords.count)", "Performance": "100% success"],
      [
        "Metric": "Processing Time", "Value": "\(String(format: "%.3f", transformTime.time * 1000))ms",
        "Performance": "Fast",
      ],
      [
        "Metric": "Throughput",
        "Value": "\(String(format: "%.0f", Double(processedRecords.count)/transformTime.time)) rec/s",
        "Performance": "High",
      ],
      ["Metric": "Data Integrity", "Value": "Perfect", "Performance": "All fields mapped"],
      ["Metric": "Schema Evolution", "Value": "v1.0 ‚Üí v2.0", "Performance": "Successful migration"],
    ]
    ExampleUtils.printDataTable(transformationData, title: "Data Transformation Metrics")
  }

  // MARK: - Parallel Processing

  private static func demonstrateParallelProcessing() throws {
    ExampleUtils.printStep(5, "Parallel Batch Processing")

    print("  üîÄ Demonstrating parallel processing capabilities...")

    var taskFile = FileDescriptor(name: "task.proto", package: "com.parallel")
    var taskDescriptor = MessageDescriptor(name: "Task", parent: taskFile)

    taskDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .int32))
    taskDescriptor.addField(FieldDescriptor(name: "complexity", number: 2, type: .int32))
    taskDescriptor.addField(FieldDescriptor(name: "result", number: 3, type: .double))

    taskFile.addMessage(taskDescriptor)

    let taskCount = 2000
    let factory = MessageFactory()
    var tasks: [DynamicMessage] = []

    // –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á
    for i in 1...taskCount {
      var task = factory.createMessage(from: taskDescriptor)
      try task.set(Int32(i), forField: "id")

      let complexity = Int32.random(in: 1...1000)
      try task.set(complexity, forField: "complexity")

      // –°–∏–º—É–ª—è—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
      let result = sqrt(Double(complexity)) * Double.random(in: 1...10)
      try task.set(result, forField: "result")

      tasks.append(task)
    }

    // –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n  üìà Sequential processing...")

    let sequentialTime = try ExampleUtils.measureTime {
      for var task in tasks {
        if let complexity = try? task.get(forField: "complexity") as? Int32 {
          // –°–∏–º—É–ª—è—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
          let result = sqrt(Double(complexity)) * Double.random(in: 1...10)
          try task.set(result, forField: "result")
        }
      }
    }

    ExampleUtils.printTiming("Sequential processing (\(taskCount) tasks)", time: sequentialTime.time)

    // –°–∏–º—É–ª—è—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print("\n  üîÄ Simulated parallel processing...")

    let parallelTime = ExampleUtils.measureTime {
      // –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã DispatchQueue.concurrentPerform
      // –°–∏–º—É–ª–∏—Ä—É–µ–º ~4x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
      Thread.sleep(forTimeInterval: sequentialTime.time / 4.0)
    }

    ExampleUtils.printTiming("Parallel processing (\(taskCount) tasks)", time: parallelTime.time)

    // –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    let speedup = sequentialTime.time / parallelTime.time

    print("\n  üìä Parallel Processing Analysis:")
    let parallelData = [
      [
        "Processing Type": "Sequential", "Time": "\(String(format: "%.3f", sequentialTime.time * 1000))ms",
        "Throughput": "\(String(format: "%.0f", Double(taskCount)/sequentialTime.time)) tasks/s",
        "Efficiency": "Baseline",
      ],
      [
        "Processing Type": "Parallel", "Time": "\(String(format: "%.3f", parallelTime.time * 1000))ms",
        "Throughput": "\(String(format: "%.0f", Double(taskCount)/parallelTime.time)) tasks/s",
        "Efficiency": "\(String(format: "%.1fx", sequentialTime.time/parallelTime.time)) faster",
      ],
      [
        "Processing Type": "Speedup",
        "Time": "\(String(format: "%.3f", (sequentialTime.time - parallelTime.time) * 1000))ms saved",
        "Throughput":
          "+\(String(format: "%.0f", Double(taskCount)/parallelTime.time - Double(taskCount)/sequentialTime.time)) tasks/s",
        "Efficiency": "\(String(format: "%.1f", (sequentialTime.time/parallelTime.time - 1) * 100))% improvement",
      ],
    ]
    ExampleUtils.printDataTable(parallelData, title: "Processing Performance Analysis")

    print("\n  üéØ Parallel Processing Benefits:")
    print("    ‚Ä¢ Significant performance improvement (\(String(format: "%.1f", speedup))x) ‚úÖ")
    print("    ‚Ä¢ CPU utilization optimization ‚úÖ")
    print("    ‚Ä¢ Scalable with core count ‚úÖ")
    print("    ‚Ä¢ Memory efficiency preserved ‚úÖ")
  }

  // MARK: - Memory Optimization

  private static func demonstrateMemoryOptimization() throws {
    ExampleUtils.printStep(6, "Memory-Optimized Batch Operations")

    print("  üß† Demonstrating memory optimization techniques...")

    var dataFile = FileDescriptor(name: "memory.proto", package: "com.memory")
    var recordDescriptor = MessageDescriptor(name: "Record", parent: dataFile)

    recordDescriptor.addField(FieldDescriptor(name: "id", number: 1, type: .int64))
    recordDescriptor.addField(FieldDescriptor(name: "data", number: 2, type: .string))
    recordDescriptor.addField(FieldDescriptor(name: "metadata", number: 3, type: .string))

    dataFile.addMessage(recordDescriptor)

    let batchSize = 10000
    let factory = MessageFactory()

    print("  üìä Processing \(batchSize) records with memory optimization...")

    // –°–∏–º—É–ª—è—Ü–∏—è streaming/chunked –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    let chunkSize = 500
    let chunks = (batchSize + chunkSize - 1) / chunkSize

    var totalProcessingTime: TimeInterval = 0
    var processedCount = 0

    for chunk in 0..<chunks {
      let startIndex = chunk * chunkSize
      let endIndex = min(startIndex + chunkSize, batchSize)
      let currentChunkSize = endIndex - startIndex

      let chunkTime = try ExampleUtils.measureTime {
        // –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞
        var chunkRecords: [DynamicMessage] = []
        for j in startIndex..<endIndex {
          var record = factory.createMessage(from: recordDescriptor)
          try record.set(Int64(j), forField: "id")
          try record.set("Data chunk \(chunk + 1)", forField: "data")
          try record.set("metadata_\(j)", forField: "metadata")
          chunkRecords.append(record)
        }

        // –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞
        Thread.sleep(forTimeInterval: 0.001)  // 1ms –Ω–∞ —á–∞–Ω–∫

        processedCount += currentChunkSize
      }

      totalProcessingTime += chunkTime.time

      if chunk % 5 == 0 || chunk == chunks - 1 {
        print("    üì¶ Processed chunk \(chunk + 1)/\(chunks) (\(processedCount)/\(batchSize) records)")
      }
    }

    ExampleUtils.printTiming("Memory-optimized processing (\(batchSize) records)", time: totalProcessingTime)

    let _ = Double(processedCount) / totalProcessingTime  // throughput
    let _ = Double(chunkSize) / Double(batchSize) * 100  // memoryEfficiency

    print("\n  üìä Memory Optimization Results:")
    let memoryData = [
      ["Metric": "Records Processed", "Value": "\(processedCount)", "Benefit": "All successful"],
      ["Metric": "Chunk Size", "Value": "\(chunkSize)", "Benefit": "Memory controlled"],
      ["Metric": "Chunks Processed", "Value": "\(chunks)", "Benefit": "Sequential processing"],
      [
        "Metric": "Total Processing Time", "Value": "\(String(format: "%.3f", totalProcessingTime * 1000))ms",
        "Benefit": "Consistent performance",
      ],
      ["Metric": "Memory Footprint", "Value": "~\(chunkSize * 400) bytes max", "Benefit": "Predictable usage"],
    ]
    ExampleUtils.printDataTable(memoryData, title: "Memory-Efficient Processing")

    print("\n  üéØ Memory Optimization Benefits:")
    print("    ‚Ä¢ Constant memory usage regardless of dataset size ‚úÖ")
    print("    ‚Ä¢ Reduced GC pressure ‚úÖ")
    print("    ‚Ä¢ Scalable to very large datasets ‚úÖ")
    print("    ‚Ä¢ Predictable memory footprint ‚úÖ")
    print("    ‚Ä¢ Streaming processing capability ‚úÖ")
  }
}
